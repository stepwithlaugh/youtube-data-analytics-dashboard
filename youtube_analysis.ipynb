{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80357992-9ae5-4444-ac7f-c92c67c6e5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving channels...\n",
      "Saved: channels.csv (8 rows), videos.csv (476 rows), features.csv (476 rows)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Add your API KEY below\n",
    "os.environ[\"YT_API_KEY\"] = \"\"\n",
    "API_KEY = os.getenv(\"YT_API_KEY\")\n",
    "if not API_KEY:\n",
    "    sys.exit(\"Please set environment variable YT_API_KEY with your YouTube Data API v3 key.\")\n",
    "\n",
    "YOUTUBE_API = \"https://www.googleapis.com/youtube/v3\"\n",
    "\n",
    "# -----------------------------\n",
    "# TODO: Paste your channels here\n",
    "# You can use full URLs (e.g., \"https://www.youtube.com/@AlexTheAnalyst\")\n",
    "# OR just handles like \"@AlexTheAnalyst\"\n",
    "# OR channel URLs like \"https://www.youtube.com/channel/UC123...\"\n",
    "# -----------------------------\n",
    "CHANNEL_URLS = [\n",
    "     \"https://www.youtube.com/@AlexTheAnalyst\",\n",
    "     \"https://www.youtube.com/@codebasics\",\n",
    "     \"https://www.youtube.com/@statquest\",\n",
    "     \"https://www.youtube.com/@3blue1brown\",\n",
    "     \"https://www.youtube.com/@TwoMinutePapers\",\n",
    "     \"https://www.youtube.com/@sentdex\",\n",
    "     \"https://www.youtube.com/@coreyms\",\n",
    "     \"https://www.youtube.com/@TinaHuang1\",\n",
    "]\n",
    "\n",
    "# ------------- Helpers --------------\n",
    "\n",
    "HANDLE_RE = re.compile(r\"(?:https?://(?:www\\.)?youtube\\.com/)?@([A-Za-z0-9_.-]+)\")\n",
    "CHANNEL_ID_RE = re.compile(r\"(?:https?://(?:www\\.)?youtube\\.com/)?channel/([A-Za-z0-9_-]{20,})\")\n",
    "\n",
    "def extract_handle_or_channel_id(url_or_handle: str):\n",
    "    s = url_or_handle.strip()\n",
    "    # channel ID?\n",
    "    m = CHANNEL_ID_RE.match(s)\n",
    "    if m:\n",
    "        return {\"type\": \"channel_id\", \"value\": m.group(1)}\n",
    "    # handle?\n",
    "    if s.startswith(\"@\"):\n",
    "        return {\"type\": \"handle\", \"value\": s[1:]}\n",
    "    m = HANDLE_RE.match(s)\n",
    "    if m:\n",
    "        return {\"type\": \"handle\", \"value\": m.group(1)}\n",
    "    # last resort: treat as search query\n",
    "    return {\"type\": \"search\", \"value\": s}\n",
    "\n",
    "def yt_get(path, **params):\n",
    "    params[\"key\"] = API_KEY\n",
    "    r = requests.get(f\"{YOUTUBE_API}/{path}\", params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def resolve_channel_id(item):\n",
    "    \"\"\"Resolve input to a canonical channelId using search (robust for handles).\"\"\"\n",
    "    itype = item[\"type\"]\n",
    "    val = item[\"value\"]\n",
    "\n",
    "    if itype == \"channel_id\":\n",
    "        return val\n",
    "\n",
    "    if itype in (\"handle\", \"search\"):\n",
    "        # Use search to find the channel\n",
    "        # q = handle or free text; type=channel limits results to channels\n",
    "        data = yt_get(\"search\",\n",
    "                      part=\"snippet\",\n",
    "                      q=val,\n",
    "                      type=\"channel\",\n",
    "                      maxResults=1)\n",
    "        items = data.get(\"items\", [])\n",
    "        if not items:\n",
    "            raise ValueError(f\"Could not resolve channel from: {val}\")\n",
    "        return items[0][\"snippet\"][\"channelId\"]\n",
    "\n",
    "    raise ValueError(f\"Unsupported identifier: {item}\")\n",
    "\n",
    "def iso8601_duration_to_seconds(iso_dur: str) -> int:\n",
    "    \"\"\"\n",
    "    Parse ISO 8601 durations like 'PT12M34S', 'PT1H2M', 'PT45S', 'P0D', etc.\n",
    "    \"\"\"\n",
    "    # Pattern covers H, M, S; days/months/years are (practically) not used by YouTube durations\n",
    "    pattern = re.compile(r'^P(?:\\d+Y)?(?:\\d+M)?(?:\\d+D)?(?:T(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?)?$')\n",
    "    m = pattern.match(iso_dur)\n",
    "    if not m:\n",
    "        return 0\n",
    "    h = int(m.group(1) or 0)\n",
    "    m_ = int(m.group(2) or 0)\n",
    "    s = int(m.group(3) or 0)\n",
    "    return h * 3600 + m_ * 60 + s\n",
    "\n",
    "def safe_int(v):\n",
    "    try:\n",
    "        return int(v)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def is_short_video(duration_seconds: int, title: str) -> bool:\n",
    "    title_lower = (title or \"\").lower()\n",
    "    return (duration_seconds is not None and duration_seconds <= 60) or (\"#short\" in title_lower or \"#shorts\" in title_lower)\n",
    "\n",
    "FAMILIES = [\n",
    "    (\"python\", [\"python\", \"pandas\", \"numpy\", \"polars\", \"jupyter\"]),\n",
    "    (\"r\", [\" r \", \"tidyverse\", \"dplyr\", \"ggplot\", \"shiny\"]),\n",
    "    (\"sql\", [\n",
    "        \"sql\", \"postgres\", \"mysql\", \"sqlite\", \"bigquery\", \"redshift\", \"snowflake\",\n",
    "        \"select \", \" join\", \"cte\", \"window function\"\n",
    "    ]),\n",
    "    (\"ml\", [\"machine learning\", \" ml \", \"scikit\", \"sklearn\", \"xgboost\", \"lightgbm\"]),\n",
    "    (\"deep learning\", [\"deep learning\", \"neural network\", \"pytorch\", \"tensorflow\", \"llm\", \"transformer\"]),\n",
    "    (\"genai/llm\", [\"chatgpt\", \"gpt\", \"llama\", \"langchain\", \"rag\", \"prompt\"]),\n",
    "    (\"nlp\", [\"nlp\", \"token\", \"bert\", \"gpt-\"]),\n",
    "    (\"computer vision\", [\"computer vision\", \"opencv\", \"yolo\"]),\n",
    "    (\"time series\", [\"time series\", \"forecast\", \"arima\", \"prophet\"]),\n",
    "    (\"statistics\", [\"statistics\", \"regression\", \"hypothesis\", \"p-value\", \"bayes\", \"probability\"]),\n",
    "    (\"data viz\", [\"visualization\", \"data viz\", \"plotly\", \"tableau\", \"power bi\", \"dashboard\",\n",
    "                  \"matplotlib\", \"seaborn\", \"ggplot\"]),\n",
    "    (\"spark/databricks\", [\"spark\", \"databricks\"]),\n",
    "    (\"airflow\", [\"airflow\"]),\n",
    "    (\"excel\", [\"excel\", \"vlookup\", \"xlookup\", \"pivot\", \"power query\"]),\n",
    "    (\"cloud/mlops\", [\"aws\", \"gcp\", \"azure\", \"s3\", \"mlflow\", \"docker\", \"kubernetes\", \"mlops\"]),\n",
    "    (\"career/interview\", [\"interview\", \"resume\", \"cv\", \"portfolio\", \"career\", \"job\",\n",
    "                          \"roadmap\", \"my path\", \"how i became\"]),\n",
    "    (\"projects/case\", [\"project\", \"case study\", \"end-to-end\", \"capstone\"]),\n",
    "    (\"tutorial/guide\", [\"tutorial\", \"guide\", \"crash course\", \"step-by-step\", \"hands-on\"]),\n",
    "    (\"math\", [\"calculus\", \"linear algebra\", \"eigen\", \"gradient\", \"matrix\", \"algebra\"]),\n",
    "    (\"livestream/qa\", [\"live\", \"livestream\", \"q&a\", \"ama\"]),\n",
    "]\n",
    "\n",
    "def _norm_text(s: str) -> str:\n",
    "    if not s: return \"\"\n",
    "    # add spaces around punctuation to help token boundaries\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[_/\\\\\\-]+\", \" \", s)\n",
    "    return f\" {s} \"\n",
    "\n",
    "def extract_topics_from_text(title: str = \"\", description: str = \"\", tags: str = \"\"):\n",
    "    \"\"\"Return up to 3 topic labels based on lightweight keyword hits across title/desc/tags.\"\"\"\n",
    "    t = _norm_text(\" \".join([title or \"\", description or \"\", \" \".join(tags) if isinstance(tags, list) else (tags or \"\")]))\n",
    "\n",
    "    hits = []\n",
    "    for label, kws in FAMILIES:\n",
    "        if any(kw in t for kw in kws):\n",
    "            hits.append(label)\n",
    "\n",
    "    # de-dup while preserving order\n",
    "    uniq = []\n",
    "    for h in hits:\n",
    "        if h not in uniq:\n",
    "            uniq.append(h)\n",
    "\n",
    "    # Fallback if nothing matched\n",
    "    if not uniq:\n",
    "        uniq = [\"general/data\"]\n",
    "\n",
    "    # Return up to 3; you can keep first as primary, second as secondary\n",
    "    return uniq[:3]\n",
    "\n",
    "def to_utc_dt(iso_str):\n",
    "    return datetime.fromisoformat(iso_str.replace(\"Z\", \"+00:00\")).astimezone(timezone.utc)\n",
    "\n",
    "def channel_details(channel_id):\n",
    "    data = yt_get(\"channels\",\n",
    "                  part=\"snippet,statistics,brandingSettings,contentDetails\",\n",
    "                  id=channel_id)\n",
    "\n",
    "    items = data.get(\"items\", [])\n",
    "    if not items:\n",
    "        return None\n",
    "    it = items[0]\n",
    "\n",
    "    snippet = it.get(\"snippet\", {})\n",
    "    stats = it.get(\"statistics\", {})\n",
    "    branding = it.get(\"brandingSettings\", {})\n",
    "    # keywords can be a long string in brandingSettings.channel.keywords\n",
    "    keywords = (branding.get(\"channel\", {}) or {}).get(\"keywords\")\n",
    "\n",
    "    return {\n",
    "        \"channel_id\": channel_id,\n",
    "        \"channel_title\": snippet.get(\"title\"),\n",
    "        \"custom_url\": snippet.get(\"customUrl\"),\n",
    "        \"published_at\": snippet.get(\"publishedAt\"),\n",
    "        \"country\": snippet.get(\"country\"),\n",
    "        \"default_language\": snippet.get(\"defaultLanguage\"),\n",
    "        \"subscribers\": safe_int(stats.get(\"subscriberCount\")),\n",
    "        \"lifetime_views\": safe_int(stats.get(\"viewCount\")),\n",
    "        \"video_count\": safe_int(stats.get(\"videoCount\")),\n",
    "        \"keywords\": keywords\n",
    "    }\n",
    "\n",
    "def list_channel_videos_last12m(channel_id, max_items=300):\n",
    "    \"\"\"Use search to fetch recent videos within last 12 months (or up to max_items).\"\"\"\n",
    "    published_after = (datetime.now(timezone.utc) - timedelta(days=365)).isoformat().replace(\"+00:00\", \"Z\")\n",
    "\n",
    "    videos = []\n",
    "    page_token = None\n",
    "\n",
    "    while True:\n",
    "        data = yt_get(\"search\",\n",
    "                      part=\"snippet\",\n",
    "                      channelId=channel_id,\n",
    "                      type=\"video\",\n",
    "                      order=\"date\",\n",
    "                      publishedAfter=published_after,\n",
    "                      maxResults=50,\n",
    "                      pageToken=page_token if page_token else None)\n",
    "        items = data.get(\"items\", [])\n",
    "        for it in items:\n",
    "            videos.append({\n",
    "                \"video_id\": it[\"id\"][\"videoId\"],\n",
    "                \"title\": it[\"snippet\"][\"title\"],\n",
    "                \"published_at\": it[\"snippet\"][\"publishedAt\"],\n",
    "                \"description\": it[\"snippet\"].get(\"description\"),\n",
    "                \"channel_id\": channel_id\n",
    "            })\n",
    "            if len(videos) >= max_items:\n",
    "                break\n",
    "        if len(videos) >= max_items:\n",
    "            break\n",
    "        page_token = data.get(\"nextPageToken\")\n",
    "        if not page_token:\n",
    "            break\n",
    "\n",
    "    return videos\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def enrich_videos_stats_and_details(video_rows):\n",
    "    \"\"\"Call videos.list in batches to add statistics, contentDetails, topicCategories, tags, etc.\"\"\"\n",
    "    if not video_rows:\n",
    "        return video_rows\n",
    "\n",
    "    id_list = [v[\"video_id\"] for v in video_rows]\n",
    "\n",
    "    id_to_details = {}\n",
    "    for batch in chunked(id_list, 50):\n",
    "        data = yt_get(\"videos\",\n",
    "                      part=\"snippet,contentDetails,statistics,topicDetails\",\n",
    "                      id=\",\".join(batch))\n",
    "        for it in data.get(\"items\", []):\n",
    "            vid = it[\"id\"]\n",
    "            snip = it.get(\"snippet\", {})\n",
    "            stats = it.get(\"statistics\", {})\n",
    "            cdet = it.get(\"contentDetails\", {})\n",
    "            tdet = it.get(\"topicDetails\", {}) or {}\n",
    "\n",
    "            tags = snip.get(\"tags\") or []\n",
    "            topic_categories = tdet.get(\"topicCategories\") or []\n",
    "            id_to_details[vid] = {\n",
    "                \"duration_sec\": iso8601_duration_to_seconds(cdet.get(\"duration\", \"PT0S\")),\n",
    "                \"view_count\": safe_int(stats.get(\"viewCount\")),\n",
    "                \"like_count\": safe_int(stats.get(\"likeCount\")),\n",
    "                \"comment_count\": safe_int(stats.get(\"commentCount\")),\n",
    "                \"made_for_kids\": snip.get(\"madeForKids\"),\n",
    "                \"live_flag\": snip.get(\"liveBroadcastContent\"),\n",
    "                \"default_audio_language\": snip.get(\"defaultAudioLanguage\"),\n",
    "                \"topic_categories\": \"|\".join(topic_categories) if topic_categories else None,\n",
    "                \"tags\": \"|\".join(tags) if tags else None,\n",
    "                \"full_title\": snip.get(\"title\"),  # overrides if different casing\n",
    "                \"thumbnails\": json.dumps(snip.get(\"thumbnails\", {})),\n",
    "            }\n",
    "        time.sleep(0.1)  # be gentle with quota\n",
    "\n",
    "    # merge\n",
    "    out = []\n",
    "    for row in video_rows:\n",
    "        det = id_to_details.get(row[\"video_id\"], {})\n",
    "        merged = {**row, **det}\n",
    "        out.append(merged)\n",
    "    return out\n",
    "\n",
    "def compute_features_df(videos_df, channels_df):\n",
    "    if videos_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    now = datetime.now(timezone.utc)\n",
    "\n",
    "    def _age_days(published_at):\n",
    "        try:\n",
    "            dt = to_utc_dt(published_at)\n",
    "            days = (now - dt).total_seconds() / 86400.0\n",
    "            return max(1.0, days)\n",
    "        except:\n",
    "            return 1.0\n",
    "\n",
    "    videos_df[\"age_days\"] = videos_df[\"published_at\"].apply(_age_days)\n",
    "    videos_df[\"views_per_day\"] = videos_df.apply(\n",
    "        lambda r: (r.get(\"view_count\") or 0) / r[\"age_days\"], axis=1\n",
    "    )\n",
    "\n",
    "    # engagement proxies\n",
    "    def per_1k(n, denom):\n",
    "        if not denom or denom == 0 or n is None:\n",
    "            return 0.0\n",
    "        return (n / denom) * 1000.0\n",
    "\n",
    "    videos_df[\"likes_per_1k\"] = videos_df.apply(\n",
    "        lambda r: per_1k(r.get(\"like_count\"), r.get(\"view_count\")), axis=1\n",
    "    )\n",
    "    videos_df[\"comments_per_1k\"] = videos_df.apply(\n",
    "        lambda r: per_1k(r.get(\"comment_count\"), r.get(\"view_count\")), axis=1\n",
    "    )\n",
    "    videos_df[\"engagement_rate\"] = videos_df.apply(\n",
    "        lambda r: ((r.get(\"like_count\") or 0) + (r.get(\"comment_count\") or 0)) / (r.get(\"view_count\") or 1),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # value density\n",
    "    def views_per_minute(r):\n",
    "        dur = r.get(\"duration_sec\") or 0\n",
    "        if dur <= 0:\n",
    "            return None\n",
    "        return (r.get(\"view_count\") or 0) / (dur / 60.0)\n",
    "    videos_df[\"views_per_min\"] = videos_df.apply(views_per_minute, axis=1)\n",
    "\n",
    "    # title stats\n",
    "    videos_df[\"title_len\"] = videos_df[\"title\"].fillna(\"\").apply(len)\n",
    "    videos_df[\"emoji_cnt\"] = videos_df[\"title\"].fillna(\"\").apply(\n",
    "        lambda s: sum(1 for ch in s if ord(ch) > 10000)\n",
    "    )\n",
    "    videos_df[\"question_mark_flag\"] = videos_df[\"title\"].fillna(\"\").apply(lambda s: \"?\" in s)\n",
    "\n",
    "    # Shorts flag\n",
    "    videos_df[\"is_short\"] = videos_df.apply(\n",
    "        lambda r: is_short_video(int(r.get(\"duration_sec\") or 0), r.get(\"title\") or \"\"),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # time features\n",
    "    def _weekday(iso_ts):\n",
    "        try:\n",
    "            return to_utc_dt(iso_ts).weekday()  # 0=Mon\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def _hour(iso_ts):\n",
    "        try:\n",
    "            return to_utc_dt(iso_ts).hour\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    videos_df[\"weekday\"] = videos_df[\"published_at\"].apply(_weekday)\n",
    "    videos_df[\"hour\"] = videos_df[\"published_at\"].apply(_hour)\n",
    "\n",
    "    # topic tagging\n",
    "    def topics_from_row(r):\n",
    "        labs = extract_topics_from_text(\n",
    "            title=r.get(\"title\", \"\"),\n",
    "            description=r.get(\"description\", \"\"),\n",
    "            tags=r.get(\"tags\", []),   # string or list — the extractor handles both\n",
    "        )\n",
    "        return pd.Series(\n",
    "            {\n",
    "                \"topic_primary\":  labs[0] if len(labs) > 0 else \"general/data\",\n",
    "                \"topic_secondary\": labs[1] if len(labs) > 1 else None,\n",
    "                # optional:\n",
    "                # \"topic_third\":     labs[2] if len(labs) > 2 else None,\n",
    "            },\n",
    "            dtype=\"object\",\n",
    "        )\n",
    "\n",
    "    topics_df = videos_df.apply(topics_from_row, axis=1)\n",
    "    videos_df = pd.concat(\n",
    "    [videos_df.drop(columns=[\"topic_primary\", \"topic_secondary\"], errors=\"ignore\"), topics_df],\n",
    "    axis=1,\n",
    "    )\n",
    "\n",
    "\n",
    "    # views_per_sub (join subs)\n",
    "    submap = dict(zip(channels_df[\"channel_id\"], channels_df[\"subscribers\"]))\n",
    "    videos_df[\"subscribers\"] = videos_df[\"channel_id\"].map(submap)\n",
    "    def vps(r):\n",
    "        subs = r.get(\"subscribers\") or 0\n",
    "        if subs <= 0:\n",
    "            return None\n",
    "        return (r.get(\"view_count\") or 0) / subs\n",
    "    videos_df[\"views_per_sub\"] = videos_df.apply(vps, axis=1)\n",
    "\n",
    "    # Build features.csv\n",
    "    features_cols = [\n",
    "        \"video_id\", \"channel_id\", \"title\", \"published_at\",\n",
    "        \"age_days\", \"views_per_day\", \"engagement_rate\",\n",
    "        \"likes_per_1k\", \"comments_per_1k\", \"views_per_min\",\n",
    "        \"title_len\", \"emoji_cnt\", \"question_mark_flag\",\n",
    "        \"duration_sec\", \"is_short\", \"weekday\", \"hour\",\n",
    "        \"topic_primary\", \"topic_secondary\", \"views_per_sub\"\n",
    "    ]\n",
    "    features_df = videos_df[features_cols].copy()\n",
    "    return features_df, videos_df\n",
    "\n",
    "# ------------- Main --------------\n",
    "\n",
    "def main():\n",
    "    if not CHANNEL_URLS:\n",
    "        print(\"Please add channel links/handles to CHANNEL_URLS and re-run.\")\n",
    "        return\n",
    "\n",
    "    print(\"Resolving channels...\")\n",
    "    channel_ids = []\n",
    "    for raw in CHANNEL_URLS:\n",
    "        ident = extract_handle_or_channel_id(raw)\n",
    "        cid = resolve_channel_id(ident)\n",
    "        channel_ids.append((raw, cid))\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # Channels info\n",
    "    channels = []\n",
    "    for raw, cid in channel_ids:\n",
    "        info = channel_details(cid)\n",
    "        if info:\n",
    "            channels.append(info)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    channels_df = pd.DataFrame(channels)\n",
    "    if channels_df.empty:\n",
    "        print(\"No channels resolved; exiting.\")\n",
    "        return\n",
    "\n",
    "    # Videos (last 12 months up to 300)\n",
    "    videos = []\n",
    "    for raw, cid in channel_ids:\n",
    "        vids_meta = list_channel_videos_last12m(cid, max_items=300)\n",
    "        videos.extend(vids_meta)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    # Enrich videos with stats/details\n",
    "    videos = enrich_videos_stats_and_details(videos)\n",
    "    videos_df = pd.DataFrame(videos)\n",
    "\n",
    "    # Compute features\n",
    "    features_df, full_videos_df = compute_features_df(videos_df, channels_df)\n",
    "\n",
    "    # Save CSVs\n",
    "    channels_df.to_csv(\"channels.csv\", index=False)\n",
    "    full_videos_df.to_csv(\"videos.csv\", index=False)\n",
    "    features_df.to_csv(\"features.csv\", index=False)\n",
    "\n",
    "    print(f\"Saved: channels.csv ({len(channels_df)} rows), \"\n",
    "          f\"videos.csv ({len(full_videos_df)} rows), \"\n",
    "          f\"features.csv ({len(features_df)} rows)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae83befb-1731-4532-be1e-e77a46314f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_published_at(df, col=\"published_at\"):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes a datetime column (default: 'published_at')\n",
    "    - Handles trailing 'Z' → '+00:00'\n",
    "    - Handles fractional seconds vs no fractions\n",
    "    - Ensures timezone-aware (UTC)\n",
    "    - Returns the DataFrame with parsed column\n",
    "    \"\"\"\n",
    "\n",
    "    # Work on a copy of the column as string\n",
    "    pub = df[col].astype(str).str.strip()\n",
    "\n",
    "    # Normalize common ISO patterns\n",
    "    pub = pub.str.replace(\"Z\", \"+00:00\", regex=False).str.replace(\"z\", \"+00:00\", regex=False)\n",
    "\n",
    "    # First parse attempt\n",
    "    df[col] = pd.to_datetime(pub, errors=\"coerce\", utc=True)\n",
    "\n",
    "    # Fallback for rows still NaT (often no fractional seconds)\n",
    "    mask_nat = df[col].isna()\n",
    "    if mask_nat.any():\n",
    "        fallback = pd.to_datetime(pub[mask_nat], format=\"%Y-%m-%dT%H:%M:%S%z\", errors=\"coerce\")\n",
    "        df.loc[mask_nat, col] = fallback\n",
    "\n",
    "    # Optional logging\n",
    "    n_nat = df[col].isna().sum()\n",
    "    if n_nat > 0:\n",
    "        print(f\"[WARN] {n_nat} rows in '{col}' could not be parsed.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766b74e5-fe63-4b96-a805-7c8629165c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   channel_id        8 non-null      object \n",
      " 1   channel_title     8 non-null      object \n",
      " 2   custom_url        8 non-null      object \n",
      " 3   published_at      8 non-null      object \n",
      " 4   country           8 non-null      object \n",
      " 5   default_language  0 non-null      float64\n",
      " 6   subscribers       8 non-null      int64  \n",
      " 7   lifetime_views    8 non-null      int64  \n",
      " 8   video_count       8 non-null      int64  \n",
      " 9   keywords          8 non-null      object \n",
      "dtypes: float64(1), int64(3), object(6)\n",
      "memory usage: 772.0+ bytes\n",
      "None\n",
      "                 channel_id                channel_title        custom_url  \\\n",
      "0  UC7cs8q-gJRlGwj4A8OmCmXg             Alex The Analyst   @alextheanalyst   \n",
      "1  UCh9nVJoWXmFb7sLApWGcLPQ                   codebasics       @codebasics   \n",
      "2  UCtYLUTtgS3k1Fg4y5tAhLbw  StatQuest with Josh Starmer        @statquest   \n",
      "3  UCYO_jab_esuFRV4b17AJtAw                  3Blue1Brown      @3blue1brown   \n",
      "4  UCbfYPyITQ-7l4upoX8nvctg            Two Minute Papers  @twominutepapers   \n",
      "\n",
      "                  published_at country  default_language  subscribers  \\\n",
      "0  2020-01-08T05:04:24.970712Z      US               NaN      1140000   \n",
      "1         2015-11-07T17:29:46Z      US               NaN      1370000   \n",
      "2         2011-05-24T01:52:48Z      US               NaN      1480000   \n",
      "3         2015-03-03T23:11:55Z      US               NaN      7600000   \n",
      "4         2006-08-18T00:05:41Z      HU               NaN      1680000   \n",
      "\n",
      "   lifetime_views  video_count  \\\n",
      "0        53686282          389   \n",
      "1       140793273         1104   \n",
      "2        82588243          291   \n",
      "3       674504510          218   \n",
      "4       154349863          996   \n",
      "\n",
      "                                            keywords  \n",
      "0  \"Data Analyst\" \"Data Analyst Salary\" \"How to b...  \n",
      "1  \"programming tutorial\" python git github \"juli...  \n",
      "2  Statistics \"Machine Learning\" \"Data Science\" S...  \n",
      "3                                        Mathematics  \n",
      "4  \"two minute papers\" ai \"machine learning\" soft...   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load your CSVs\n",
    "channels = pd.read_csv(\"channels.csv\")\n",
    "videos = pd.read_csv(\"videos.csv\")\n",
    "features = pd.read_csv(\"features.csv\")\n",
    "\n",
    "# --- Quick overviews ---\n",
    "print(\"Channels dataset:\")\n",
    "print(channels.info())\n",
    "print(channels.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d483b312-5190-4385-a221-14001df1f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = channels.drop(columns=[\"default_language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdbce970-f8ab-4144-a761-c6d91cfe1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = clean_published_at(channels, col=\"published_at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69adbdfe-777d-4a71-903d-b91ec9e9cde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_id        0\n",
       "channel_title     0\n",
       "custom_url        0\n",
       "published_at      0\n",
       "country           0\n",
       "subscribers       0\n",
       "lifetime_views    0\n",
       "video_count       0\n",
       "keywords          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels.dtypes\n",
    "# channel_id/object, channel_title/object, custom_url/object,\n",
    "# published_at/datetime64[ns, UTC], country/object,\n",
    "# subscribers/int64, lifetime_views/int64, video_count/int64, keywords/object\n",
    "\n",
    "channels.isna().sum()\n",
    "# should be 0 for published_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33599b9a-1cb6-4b87-8dee-e089590c186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype              \n",
      "---  ------          --------------  -----              \n",
      " 0   channel_id      8 non-null      object             \n",
      " 1   channel_title   8 non-null      object             \n",
      " 2   custom_url      8 non-null      object             \n",
      " 3   published_at    8 non-null      datetime64[ns, UTC]\n",
      " 4   country         8 non-null      object             \n",
      " 5   subscribers     8 non-null      int64              \n",
      " 6   lifetime_views  8 non-null      int64              \n",
      " 7   video_count     8 non-null      int64              \n",
      " 8   keywords        8 non-null      object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(3), object(5)\n",
      "memory usage: 708.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Channels dataset:\")\n",
    "print(channels.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df40797-a248-49b4-ab90-08ec8e7b0875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 476 entries, 0 to 475\n",
      "Data columns (total 32 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   video_id                476 non-null    object \n",
      " 1   title                   476 non-null    object \n",
      " 2   published_at            476 non-null    object \n",
      " 3   description             337 non-null    object \n",
      " 4   channel_id              476 non-null    object \n",
      " 5   duration_sec            476 non-null    int64  \n",
      " 6   view_count              476 non-null    int64  \n",
      " 7   like_count              476 non-null    int64  \n",
      " 8   comment_count           476 non-null    int64  \n",
      " 9   made_for_kids           0 non-null      float64\n",
      " 10  live_flag               476 non-null    object \n",
      " 11  default_audio_language  476 non-null    object \n",
      " 12  topic_categories        408 non-null    object \n",
      " 13  tags                    259 non-null    object \n",
      " 14  full_title              476 non-null    object \n",
      " 15  thumbnails              476 non-null    object \n",
      " 16  age_days                476 non-null    float64\n",
      " 17  views_per_day           476 non-null    float64\n",
      " 18  likes_per_1k            476 non-null    float64\n",
      " 19  comments_per_1k         476 non-null    float64\n",
      " 20  engagement_rate         476 non-null    float64\n",
      " 21  views_per_min           476 non-null    float64\n",
      " 22  title_len               476 non-null    int64  \n",
      " 23  emoji_cnt               476 non-null    int64  \n",
      " 24  question_mark_flag      476 non-null    bool   \n",
      " 25  is_short                476 non-null    bool   \n",
      " 26  weekday                 476 non-null    int64  \n",
      " 27  hour                    476 non-null    int64  \n",
      " 28  topic_primary           476 non-null    object \n",
      " 29  topic_secondary         126 non-null    object \n",
      " 30  subscribers             476 non-null    int64  \n",
      " 31  views_per_sub           476 non-null    float64\n",
      "dtypes: bool(2), float64(8), int64(9), object(13)\n",
      "memory usage: 112.6+ KB\n",
      "None\n",
      "      video_id                                              title  \\\n",
      "0  Rcpidz-jnZQ                                        SQL is King   \n",
      "1  QzvA7r-WndM                            What is Git and GitHub?   \n",
      "2  yhlqKsYpzgE  Alex The Analyst Q/A Livestream | Come Ask Me ...   \n",
      "3  kk5zEOQzTmQ  Data Visualization and Presentation in R | R f...   \n",
      "4  TP2OJuZhbIQ              Things I Learned as a Data Analyst p1   \n",
      "\n",
      "           published_at                                        description  \\\n",
      "0  2025-08-27T11:05:28Z                                                NaN   \n",
      "1  2025-08-26T12:00:54Z  Take my Full Git and GitHub Course: https://ww...   \n",
      "2  2025-08-21T14:09:29Z  Come ask me anything in my Weekly Q/A! In this...   \n",
      "3  2025-08-19T12:01:22Z  Take my Full R Programming for Data Analysts C...   \n",
      "4  2025-08-15T11:46:04Z                                                NaN   \n",
      "\n",
      "                 channel_id  duration_sec  view_count  like_count  \\\n",
      "0  UC7cs8q-gJRlGwj4A8OmCmXg            45        4208         196   \n",
      "1  UC7cs8q-gJRlGwj4A8OmCmXg           512        4925         228   \n",
      "2  UC7cs8q-gJRlGwj4A8OmCmXg          3673        2917         126   \n",
      "3  UC7cs8q-gJRlGwj4A8OmCmXg          1264        2693          77   \n",
      "4  UC7cs8q-gJRlGwj4A8OmCmXg            38        6881         240   \n",
      "\n",
      "   comment_count  made_for_kids  ... title_len emoji_cnt question_mark_flag  \\\n",
      "0              8            NaN  ...        11         0              False   \n",
      "1              7            NaN  ...        23         0               True   \n",
      "2             11            NaN  ...        54         0              False   \n",
      "3             12            NaN  ...        70         0              False   \n",
      "4             13            NaN  ...        37         0              False   \n",
      "\n",
      "  is_short weekday hour     topic_primary  topic_secondary  subscribers  \\\n",
      "0     True       2   11               sql              NaN      1140000   \n",
      "1    False       1   12  career/interview              NaN      1140000   \n",
      "2    False       3   14  career/interview    livestream/qa      1140000   \n",
      "3    False       1   12                 r         data viz      1140000   \n",
      "4     True       4   11      general/data              NaN      1140000   \n",
      "\n",
      "   views_per_sub  \n",
      "0       0.003691  \n",
      "1       0.004320  \n",
      "2       0.002559  \n",
      "3       0.002362  \n",
      "4       0.006036  \n",
      "\n",
      "[5 rows x 32 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Videos dataset:\")\n",
    "print(videos.info())\n",
    "print(videos.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bb09cfb-72d1-46bb-8bfa-e9d9591ee5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_keep = [\n",
    "    \"video_id\",\"channel_id\",\"title\",\"published_at\",\n",
    "    \"duration_sec\",\"is_short\",\"live_flag\",\n",
    "    \"view_count\",\"like_count\",\"comment_count\",\n",
    "    \"age_days\",\"views_per_day\",\"likes_per_1k\",\"comments_per_1k\",\n",
    "    \"engagement_rate\",\"views_per_min\",\"views_per_sub\",\n",
    "    \"weekday\",\"hour\",\n",
    "    \"topic_primary\",\"topic_secondary\",\"tags\",\"topic_categories\",\n",
    "    \"subscribers\",\"default_audio_language\"\n",
    "]\n",
    "\n",
    "videos = videos[cols_keep].copy()\n",
    "\n",
    "# If you want to drop text-heavy columns now:\n",
    "videos = videos.drop(columns=[\"tags\",\"topic_categories\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9623daf-5225-4ba3-b700-fb19c2e388d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = clean_published_at(videos, col=\"published_at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b22b5014-5557-4590-af1f-e4b47a5781ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 476 entries, 0 to 475\n",
      "Data columns (total 23 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                476 non-null    object             \n",
      " 1   channel_id              476 non-null    object             \n",
      " 2   title                   476 non-null    object             \n",
      " 3   published_at            476 non-null    datetime64[ns, UTC]\n",
      " 4   duration_sec            476 non-null    int64              \n",
      " 5   is_short                476 non-null    bool               \n",
      " 6   live_flag               476 non-null    object             \n",
      " 7   view_count              476 non-null    int64              \n",
      " 8   like_count              476 non-null    int64              \n",
      " 9   comment_count           476 non-null    int64              \n",
      " 10  age_days                476 non-null    float64            \n",
      " 11  views_per_day           476 non-null    float64            \n",
      " 12  likes_per_1k            476 non-null    float64            \n",
      " 13  comments_per_1k         476 non-null    float64            \n",
      " 14  engagement_rate         476 non-null    float64            \n",
      " 15  views_per_min           476 non-null    float64            \n",
      " 16  views_per_sub           476 non-null    float64            \n",
      " 17  weekday                 476 non-null    int64              \n",
      " 18  hour                    476 non-null    int64              \n",
      " 19  topic_primary           476 non-null    object             \n",
      " 20  topic_secondary         126 non-null    object             \n",
      " 21  subscribers             476 non-null    int64              \n",
      " 22  default_audio_language  476 non-null    object             \n",
      "dtypes: bool(1), datetime64[ns, UTC](1), float64(7), int64(7), object(7)\n",
      "memory usage: 82.4+ KB\n"
     ]
    }
   ],
   "source": [
    "videos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2457eec7-04b6-4406-9325-2a96acbd943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ensure datetimes are proper and preserved as UTC ---\n",
    "videos[\"published_at\"] = pd.to_datetime(videos[\"published_at\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# --- Cast IDs & labels to strings (good for Tableau) ---\n",
    "str_cols = [\n",
    "    \"video_id\",\"channel_id\",\"live_flag\",\"default_audio_language\",\n",
    "    \"topic_primary\",\"topic_secondary\",\"title\"\n",
    "]\n",
    "for c in str_cols:\n",
    "    if c in videos.columns:\n",
    "        videos[c] = videos[c].astype(\"string\")\n",
    "\n",
    "# --- Booleans as TRUE/FALSE (Tableau friendly) ---\n",
    "if \"is_short\" in videos.columns:\n",
    "    videos[\"is_short\"] = videos[\"is_short\"].astype(\"boolean\")\n",
    "\n",
    "# --- Numeric columns: keep numeric ---\n",
    "int_cols = [\"view_count\",\"like_count\",\"comment_count\",\"duration_sec\",\"subscribers\"]\n",
    "for c in int_cols:\n",
    "    if c in videos.columns:\n",
    "        videos[c] = pd.to_numeric(videos[c], errors=\"coerce\")\n",
    "\n",
    "float_cols = [\"age_days\",\"views_per_day\",\"likes_per_1k\",\"comments_per_1k\",\n",
    "              \"engagement_rate\",\"views_per_min\",\"views_per_sub\"]\n",
    "for c in float_cols:\n",
    "    if c in videos.columns:\n",
    "        videos[c] = pd.to_numeric(videos[c], errors=\"coerce\")\n",
    "\n",
    "# --- Optional: also keep weekday/hour as numbers (Tableau can bin/order) ---\n",
    "for c in [\"weekday\",\"hour\"]:\n",
    "    if c in videos.columns:\n",
    "        videos[c] = pd.to_numeric(videos[c], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b29b1f37-cd6d-4348-b1b2-c9af49b66de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 476 entries, 0 to 475\n",
      "Data columns (total 23 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   video_id                476 non-null    string             \n",
      " 1   channel_id              476 non-null    string             \n",
      " 2   title                   476 non-null    string             \n",
      " 3   published_at            476 non-null    datetime64[ns, UTC]\n",
      " 4   duration_sec            476 non-null    int64              \n",
      " 5   is_short                476 non-null    boolean            \n",
      " 6   live_flag               476 non-null    string             \n",
      " 7   view_count              476 non-null    int64              \n",
      " 8   like_count              476 non-null    int64              \n",
      " 9   comment_count           476 non-null    int64              \n",
      " 10  age_days                476 non-null    float64            \n",
      " 11  views_per_day           476 non-null    float64            \n",
      " 12  likes_per_1k            476 non-null    float64            \n",
      " 13  comments_per_1k         476 non-null    float64            \n",
      " 14  engagement_rate         476 non-null    float64            \n",
      " 15  views_per_min           476 non-null    float64            \n",
      " 16  views_per_sub           476 non-null    float64            \n",
      " 17  weekday                 476 non-null    int64              \n",
      " 18  hour                    476 non-null    int64              \n",
      " 19  topic_primary           476 non-null    string             \n",
      " 20  topic_secondary         126 non-null    string             \n",
      " 21  subscribers             476 non-null    int64              \n",
      " 22  default_audio_language  476 non-null    string             \n",
      "dtypes: boolean(1), datetime64[ns, UTC](1), float64(7), int64(7), string(7)\n",
      "memory usage: 82.9 KB\n"
     ]
    }
   ],
   "source": [
    "videos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f36803-57bf-49f2-89d6-e869c88f6111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d909ac1-c73d-4e7b-a9d4-907d958056c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a43a647e-91c4-41a2-8a51-de4bbaa10d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 476 entries, 0 to 475\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   video_id            476 non-null    object \n",
      " 1   channel_id          476 non-null    object \n",
      " 2   title               476 non-null    object \n",
      " 3   published_at        476 non-null    object \n",
      " 4   age_days            476 non-null    float64\n",
      " 5   views_per_day       476 non-null    float64\n",
      " 6   engagement_rate     476 non-null    float64\n",
      " 7   likes_per_1k        476 non-null    float64\n",
      " 8   comments_per_1k     476 non-null    float64\n",
      " 9   views_per_min       476 non-null    float64\n",
      " 10  title_len           476 non-null    int64  \n",
      " 11  emoji_cnt           476 non-null    int64  \n",
      " 12  question_mark_flag  476 non-null    bool   \n",
      " 13  duration_sec        476 non-null    int64  \n",
      " 14  is_short            476 non-null    bool   \n",
      " 15  weekday             476 non-null    int64  \n",
      " 16  hour                476 non-null    int64  \n",
      " 17  topic_primary       476 non-null    object \n",
      " 18  topic_secondary     126 non-null    object \n",
      " 19  views_per_sub       476 non-null    float64\n",
      "dtypes: bool(2), float64(7), int64(5), object(6)\n",
      "memory usage: 68.0+ KB\n",
      "None\n",
      "      video_id                channel_id  \\\n",
      "0  Rcpidz-jnZQ  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
      "1  QzvA7r-WndM  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
      "2  yhlqKsYpzgE  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
      "3  kk5zEOQzTmQ  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
      "4  TP2OJuZhbIQ  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
      "\n",
      "                                               title          published_at  \\\n",
      "0                                        SQL is King  2025-08-27T11:05:28Z   \n",
      "1                            What is Git and GitHub?  2025-08-26T12:00:54Z   \n",
      "2  Alex The Analyst Q/A Livestream | Come Ask Me ...  2025-08-21T14:09:29Z   \n",
      "3  Data Visualization and Presentation in R | R f...  2025-08-19T12:01:22Z   \n",
      "4              Things I Learned as a Data Analyst p1  2025-08-15T11:46:04Z   \n",
      "\n",
      "    age_days  views_per_day  engagement_rate  likes_per_1k  comments_per_1k  \\\n",
      "0   1.163805    3615.727543         0.048479     46.577947         1.901141   \n",
      "1   2.125309    2317.309949         0.047716     46.294416         1.421320   \n",
      "2   7.036015     414.581256         0.046966     43.195063         3.770998   \n",
      "3   9.124985     295.123771         0.033049     28.592648         4.455997   \n",
      "4  13.135610     523.843199         0.036768     34.878651         1.889260   \n",
      "\n",
      "   views_per_min  title_len  emoji_cnt  question_mark_flag  duration_sec  \\\n",
      "0    5610.666667         11          0               False            45   \n",
      "1     577.148438         23          0                True           512   \n",
      "2      47.650422         54          0               False          3673   \n",
      "3     127.832278         70          0               False          1264   \n",
      "4   10864.736842         37          0               False            38   \n",
      "\n",
      "   is_short  weekday  hour     topic_primary topic_secondary  views_per_sub  \n",
      "0      True        2    11               sql             NaN       0.003691  \n",
      "1     False        1    12  career/interview             NaN       0.004320  \n",
      "2     False        3    14  career/interview   livestream/qa       0.002559  \n",
      "3     False        1    12                 r        data viz       0.002362  \n",
      "4      True        4    11      general/data             NaN       0.006036   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Features dataset:\")\n",
    "print(features.info())\n",
    "print(features.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eef2563-75fa-418c-aff3-b697b6a308fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 476 entries, 0 to 475\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count  Dtype              \n",
      "---  ------              --------------  -----              \n",
      " 0   video_id            476 non-null    string             \n",
      " 1   channel_id          476 non-null    string             \n",
      " 2   title               476 non-null    string             \n",
      " 3   published_at        476 non-null    datetime64[ns, UTC]\n",
      " 4   age_days            476 non-null    float64            \n",
      " 5   views_per_day       476 non-null    float64            \n",
      " 6   engagement_rate     476 non-null    float64            \n",
      " 7   likes_per_1k        476 non-null    float64            \n",
      " 8   comments_per_1k     476 non-null    float64            \n",
      " 9   views_per_min       476 non-null    float64            \n",
      " 10  title_len           476 non-null    Int64              \n",
      " 11  emoji_cnt           476 non-null    Int64              \n",
      " 12  question_mark_flag  476 non-null    boolean            \n",
      " 13  duration_sec        476 non-null    Int64              \n",
      " 14  is_short            476 non-null    boolean            \n",
      " 15  weekday             476 non-null    Int64              \n",
      " 16  hour                476 non-null    Int64              \n",
      " 17  topic_primary       476 non-null    string             \n",
      " 18  topic_secondary     476 non-null    string             \n",
      " 19  views_per_sub       476 non-null    float64            \n",
      "dtypes: Int64(5), boolean(2), datetime64[ns, UTC](1), float64(7), string(5)\n",
      "memory usage: 222.6 KB\n"
     ]
    }
   ],
   "source": [
    "# 1) Parse datetime in UTC\n",
    "features[\"published_at\"] = pd.to_datetime(features[\"published_at\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# 2) Integer columns\n",
    "int_cols = [\"duration_sec\", \"title_len\", \"emoji_cnt\", \"weekday\", \"hour\"]\n",
    "for c in int_cols:\n",
    "    features[c] = pd.to_numeric(features[c], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# 3) Float columns (ratios/derived)\n",
    "float_cols = [\n",
    "    \"age_days\",\"views_per_day\",\"engagement_rate\",\"likes_per_1k\",\n",
    "    \"comments_per_1k\",\"views_per_min\",\"views_per_sub\"\n",
    "]\n",
    "for c in float_cols:\n",
    "    features[c] = pd.to_numeric(features[c], errors=\"coerce\")\n",
    "\n",
    "# 4) Booleans already okay; but enforce just in case\n",
    "for c in [\"is_short\", \"question_mark_flag\"]:\n",
    "    features[c] = features[c].astype(\"boolean\")\n",
    "\n",
    "# 5) Text columns as string (helps avoid mixed types)\n",
    "text_cols = [\"video_id\",\"channel_id\",\"title\",\"topic_primary\",\"topic_secondary\"]\n",
    "for c in text_cols:\n",
    "    features[c] = features[c].astype(\"string\")\n",
    "\n",
    "# 6) Optional: fill missing topic_secondary for Tableau filters\n",
    "features[\"topic_secondary\"] = features[\"topic_secondary\"].fillna(\"none\")\n",
    "\n",
    "# Quick sanity checks\n",
    "assert features[\"duration_sec\"].gt(0).all(skipna=True)\n",
    "assert features[\"view_count\"].ge(0).all(skipna=True) if \"view_count\" in features.columns else True\n",
    "\n",
    "features.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3251a71-52ed-4854-bfed-931f514c37f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of channels: (8, 9)\n",
      "Shape of videos: (476, 23)\n",
      "Shape of features: (476, 20)\n"
     ]
    }
   ],
   "source": [
    "# --- Quick shapes ---\n",
    "print(\"Shape of channels:\", channels.shape)\n",
    "print(\"Shape of videos:\", videos.shape)\n",
    "print(\"Shape of features:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29c2d891-12b4-49fd-a648-b454427331ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV (good for Tableau)\n",
    "channels.to_csv(\"channels_clean.csv\", index=False, encoding=\"utf-8\")\n",
    "videos.to_csv(\"videos_clean.csv\", index=False, encoding=\"utf-8\")\n",
    "features.to_csv(\"features_clean.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddfa142-4093-4af0-95f1-c84360950383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb9804-835b-4dba-953e-cc3a4197ac6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d3299-6de4-4e96-9878-b0f736debcb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3a687-39a5-48bf-b429-1d12d1134175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc59bf2-78d9-4d05-aad1-c4fdbc2d1d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
